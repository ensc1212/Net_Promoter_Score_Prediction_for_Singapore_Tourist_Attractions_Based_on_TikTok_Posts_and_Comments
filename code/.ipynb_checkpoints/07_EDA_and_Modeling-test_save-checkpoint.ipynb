{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899d2839",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdaae219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats import skew, shapiro\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479463d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer # clean and tokenize data\n",
    "from keras.preprocessing.sequence import pad_sequences #\n",
    "from keras.initializers import he_normal\n",
    "import tensorflow as tf\n",
    "import keras.backend as K # facilitate the computation of performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92f3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display purposes\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Parameter mappings to override the values in the preset seaborn style dictionaries\n",
    "color = 'black'\n",
    "sns.set_theme(rc={'grid.color': 'white', \n",
    "                  'xtick.color': color,\n",
    "                  'ytick.color': color,\n",
    "                  'axes.labelcolor': color,\n",
    "                  'text.color': color,\n",
    "                  'axes.facecolor':(0,0,0,0),\n",
    "                  'figure.facecolor':(0,0,0,0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa1677",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d9f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../datasets/train_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376542a4",
   "metadata": {},
   "source": [
    "#### Check each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9116477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31327 entries, 0 to 31326\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   post_comment         31327 non-null  object \n",
      " 1   id                   31327 non-null  object \n",
      " 2   sentence             31327 non-null  object \n",
      " 3   entity               31327 non-null  object \n",
      " 4   pos_sentiment_words  31327 non-null  object \n",
      " 5   neg_sentiment_words  31327 non-null  object \n",
      " 6   textblob             31327 non-null  float64\n",
      " 7   sentiment            31327 non-null  float64\n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d451b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sentiment'] = (train_df['sentiment'])**(1 / 1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e0bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale using minmax\n",
    "# convert to array\n",
    "y = train_df['sentiment'].array\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "mm.fit(y.reshape(-1,1))\n",
    "y = mm.transform(y.reshape(-1,1))\n",
    "\n",
    "# convert back to dataframe\n",
    "train_df['sentiment'] = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f30df1",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd139b3",
   "metadata": {},
   "source": [
    "#### Using train_test_split, the data will be split for training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a68375",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df['sentence']\n",
    "y = train_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f41afcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X train set has 24435 rows.\n",
      "The y train set has 24435 rows.\n",
      "The X test set has 6892 rows.\n",
      "The y test set has 6892 rows.\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.78,random_state=42)\n",
    "\n",
    "print(f'The X train set has {X_train.shape[0]} rows.')\n",
    "print(f'The y train set has {y_train.shape[0]} rows.')\n",
    "print(f'The X test set has {X_test.shape[0]} rows.')\n",
    "print(f'The y test set has {y_test.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c72e18",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df781b7",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b889c82d",
   "metadata": {},
   "source": [
    "#### Kickstart the modeling process by fixing the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "249a3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a255df",
   "metadata": {},
   "source": [
    "#### Instantiate variables that will be used in the model. Some of these variables are tuned to optimize for R^2 and MSE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a343bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 9800\n",
    "oov_token = \"<OOV>\"\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "embedding_dim = 16 # 16\n",
    "max_length = 200 # 100, 110"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23baf2e8",
   "metadata": {},
   "source": [
    "#### Define custom function to calculate R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cc53395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom functions to calculate R2\n",
    "def R2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) # sum of squares of residuals\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) # total sum of squares\n",
    "    # K.epsilon: Epsilon is small value that makes very little difference to the value of \n",
    "    # the denominator, but ensures that it isn't equal to exactly zero.\n",
    "    r2_score = (1 - (SS_res / (SS_tot + K.epsilon())))\n",
    "    return r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7a7df9",
   "metadata": {},
   "source": [
    "#### Initialize and fit the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61b81a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and fit the tokenizer\n",
    "tokenizer = Tokenizer(num_words=vocab_size,oov_token=oov_token)\n",
    "\n",
    "# create tokens for every word in the corpus\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# save them in word_index\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a523ff",
   "metadata": {},
   "source": [
    "#### Turn sentences in both X_train and X_test into sequences of tokens and pad them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4f65e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn sentences into sequences of tokens\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "# pad sentences so they are all the same length\n",
    "X_train_seq_padded = pad_sequences(X_train_seq, maxlen=max_length,\n",
    "                                   padding=padding_type,truncating=trunc_type)\n",
    "\n",
    "# do the same for X_test\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_seq_padded = pad_sequences(X_test_seq, maxlen=max_length,\n",
    "                                   padding=padding_type,truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953eadc3",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d87943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Create a simple model.\n",
    "    inputs = keras.Input(shape=(32,))\n",
    "    outputs = keras.layers.Dense(1)(inputs)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(), loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23501a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # top layer is an embedding, where direction of each word will be learned epoch by epoch\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    # we pool with a global average pooling, ie, adding up the vectors to get meaning\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    # this is then fed into deep neural network\n",
    "    tf.keras.layers.Dense(96, \n",
    "                          activation='relu',\n",
    "                          kernel_initializer = tf.keras.initializers.RandomNormal(mean=0., \n",
    "                                                                                  stddev=2.)),\n",
    "    tf.keras.layers.Dense(64, \n",
    "                          activation='relu'),\n",
    "    tf.keras.layers.Dense(32, \n",
    "                          activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989642ef",
   "metadata": {},
   "source": [
    "#### Get model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c6fb61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 16)           156800    \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 16)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 96)                1632      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                6208      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166753 (651.38 KB)\n",
      "Trainable params: 166753 (651.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568af48",
   "metadata": {},
   "source": [
    "#### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50449ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0009, \n",
    "                                     weight_decay=0.004,\n",
    "                                     clipvalue=2.)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse',\n",
    "                       tf.keras.metrics.RootMeanSquaredError(name='RMSE')]) # r2 defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bec54",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fa6bc4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n",
      "764/764 - 2s - loss: 0.0125 - mse: 0.0125 - RMSE: 0.1117 - val_loss: 0.0084 - val_mse: 0.0084 - val_RMSE: 0.0916 - 2s/epoch - 2ms/step\n",
      "Epoch 2/92\n",
      "764/764 - 1s - loss: 0.0045 - mse: 0.0045 - RMSE: 0.0670 - val_loss: 0.0038 - val_mse: 0.0038 - val_RMSE: 0.0614 - 1s/epoch - 1ms/step\n",
      "Epoch 3/92\n",
      "764/764 - 1s - loss: 0.0027 - mse: 0.0027 - RMSE: 0.0516 - val_loss: 0.0030 - val_mse: 0.0030 - val_RMSE: 0.0546 - 1s/epoch - 1ms/step\n",
      "Epoch 4/92\n",
      "764/764 - 1s - loss: 0.0020 - mse: 0.0020 - RMSE: 0.0444 - val_loss: 0.0029 - val_mse: 0.0029 - val_RMSE: 0.0536 - 1s/epoch - 1ms/step\n",
      "Epoch 5/92\n",
      "764/764 - 1s - loss: 0.0016 - mse: 0.0016 - RMSE: 0.0395 - val_loss: 0.0025 - val_mse: 0.0025 - val_RMSE: 0.0500 - 1s/epoch - 1ms/step\n",
      "Epoch 6/92\n",
      "764/764 - 1s - loss: 0.0013 - mse: 0.0013 - RMSE: 0.0361 - val_loss: 0.0024 - val_mse: 0.0024 - val_RMSE: 0.0487 - 1s/epoch - 1ms/step\n",
      "Epoch 7/92\n",
      "764/764 - 1s - loss: 0.0011 - mse: 0.0011 - RMSE: 0.0337 - val_loss: 0.0028 - val_mse: 0.0028 - val_RMSE: 0.0529 - 1s/epoch - 1ms/step\n",
      "Epoch 8/92\n",
      "764/764 - 1s - loss: 0.0010 - mse: 0.0010 - RMSE: 0.0317 - val_loss: 0.0023 - val_mse: 0.0023 - val_RMSE: 0.0484 - 1s/epoch - 1ms/step\n",
      "Epoch 9/92\n",
      "764/764 - 1s - loss: 8.5213e-04 - mse: 8.5213e-04 - RMSE: 0.0292 - val_loss: 0.0018 - val_mse: 0.0018 - val_RMSE: 0.0421 - 1s/epoch - 1ms/step\n",
      "Epoch 10/92\n",
      "764/764 - 1s - loss: 8.2037e-04 - mse: 8.2037e-04 - RMSE: 0.0286 - val_loss: 0.0020 - val_mse: 0.0020 - val_RMSE: 0.0446 - 1s/epoch - 1ms/step\n",
      "Epoch 11/92\n",
      "764/764 - 1s - loss: 6.7748e-04 - mse: 6.7748e-04 - RMSE: 0.0260 - val_loss: 0.0018 - val_mse: 0.0018 - val_RMSE: 0.0419 - 1s/epoch - 2ms/step\n",
      "Epoch 12/92\n",
      "764/764 - 1s - loss: 6.2167e-04 - mse: 6.2167e-04 - RMSE: 0.0249 - val_loss: 0.0018 - val_mse: 0.0018 - val_RMSE: 0.0419 - 1s/epoch - 2ms/step\n",
      "Epoch 13/92\n",
      "764/764 - 1s - loss: 5.8430e-04 - mse: 5.8430e-04 - RMSE: 0.0242 - val_loss: 0.0016 - val_mse: 0.0016 - val_RMSE: 0.0397 - 1s/epoch - 2ms/step\n",
      "Epoch 14/92\n",
      "764/764 - 1s - loss: 5.7162e-04 - mse: 5.7162e-04 - RMSE: 0.0239 - val_loss: 0.0018 - val_mse: 0.0018 - val_RMSE: 0.0427 - 1s/epoch - 2ms/step\n",
      "Epoch 15/92\n",
      "764/764 - 1s - loss: 4.9065e-04 - mse: 4.9065e-04 - RMSE: 0.0222 - val_loss: 0.0021 - val_mse: 0.0021 - val_RMSE: 0.0457 - 1s/epoch - 2ms/step\n",
      "Epoch 16/92\n",
      "764/764 - 1s - loss: 4.5737e-04 - mse: 4.5737e-04 - RMSE: 0.0214 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0386 - 1s/epoch - 2ms/step\n",
      "Epoch 17/92\n",
      "764/764 - 1s - loss: 4.3123e-04 - mse: 4.3123e-04 - RMSE: 0.0208 - val_loss: 0.0016 - val_mse: 0.0016 - val_RMSE: 0.0406 - 1s/epoch - 2ms/step\n",
      "Epoch 18/92\n",
      "764/764 - 1s - loss: 4.1961e-04 - mse: 4.1961e-04 - RMSE: 0.0205 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0383 - 1s/epoch - 2ms/step\n",
      "Epoch 19/92\n",
      "764/764 - 1s - loss: 4.1778e-04 - mse: 4.1778e-04 - RMSE: 0.0204 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0391 - 1s/epoch - 2ms/step\n",
      "Epoch 20/92\n",
      "764/764 - 1s - loss: 3.8481e-04 - mse: 3.8481e-04 - RMSE: 0.0196 - val_loss: 0.0016 - val_mse: 0.0016 - val_RMSE: 0.0397 - 1s/epoch - 2ms/step\n",
      "Epoch 21/92\n",
      "764/764 - 1s - loss: 3.6091e-04 - mse: 3.6091e-04 - RMSE: 0.0190 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0381 - 1s/epoch - 2ms/step\n",
      "Epoch 22/92\n",
      "764/764 - 1s - loss: 3.7356e-04 - mse: 3.7356e-04 - RMSE: 0.0193 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0384 - 1s/epoch - 2ms/step\n",
      "Epoch 23/92\n",
      "764/764 - 1s - loss: 3.1783e-04 - mse: 3.1783e-04 - RMSE: 0.0178 - val_loss: 0.0014 - val_mse: 0.0014 - val_RMSE: 0.0376 - 1s/epoch - 2ms/step\n",
      "Epoch 24/92\n",
      "764/764 - 1s - loss: 3.1084e-04 - mse: 3.1084e-04 - RMSE: 0.0176 - val_loss: 0.0014 - val_mse: 0.0014 - val_RMSE: 0.0369 - 1s/epoch - 2ms/step\n",
      "Epoch 25/92\n",
      "764/764 - 1s - loss: 3.2747e-04 - mse: 3.2747e-04 - RMSE: 0.0181 - val_loss: 0.0014 - val_mse: 0.0014 - val_RMSE: 0.0374 - 1s/epoch - 2ms/step\n",
      "Epoch 26/92\n",
      "764/764 - 1s - loss: 3.2159e-04 - mse: 3.2159e-04 - RMSE: 0.0179 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0385 - 1s/epoch - 2ms/step\n",
      "Epoch 27/92\n",
      "764/764 - 1s - loss: 2.8884e-04 - mse: 2.8884e-04 - RMSE: 0.0170 - val_loss: 0.0014 - val_mse: 0.0014 - val_RMSE: 0.0370 - 1s/epoch - 2ms/step\n",
      "Epoch 28/92\n",
      "764/764 - 1s - loss: 2.9384e-04 - mse: 2.9384e-04 - RMSE: 0.0171 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0384 - 1s/epoch - 2ms/step\n",
      "Epoch 29/92\n",
      "764/764 - 1s - loss: 2.7919e-04 - mse: 2.7919e-04 - RMSE: 0.0167 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0365 - 1s/epoch - 2ms/step\n",
      "Epoch 30/92\n",
      "764/764 - 1s - loss: 2.9048e-04 - mse: 2.9048e-04 - RMSE: 0.0170 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0360 - 1s/epoch - 2ms/step\n",
      "Epoch 31/92\n",
      "764/764 - 1s - loss: 2.5460e-04 - mse: 2.5460e-04 - RMSE: 0.0160 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0383 - 1s/epoch - 2ms/step\n",
      "Epoch 32/92\n",
      "764/764 - 1s - loss: 2.7731e-04 - mse: 2.7731e-04 - RMSE: 0.0167 - val_loss: 0.0014 - val_mse: 0.0014 - val_RMSE: 0.0371 - 1s/epoch - 2ms/step\n",
      "Epoch 33/92\n",
      "764/764 - 1s - loss: 2.8903e-04 - mse: 2.8903e-04 - RMSE: 0.0170 - val_loss: 0.0014 - val_mse: 0.0014 - val_RMSE: 0.0372 - 1s/epoch - 2ms/step\n",
      "Epoch 34/92\n",
      "764/764 - 1s - loss: 2.8974e-04 - mse: 2.8974e-04 - RMSE: 0.0170 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0364 - 1s/epoch - 2ms/step\n",
      "Epoch 35/92\n",
      "764/764 - 1s - loss: 2.4557e-04 - mse: 2.4557e-04 - RMSE: 0.0157 - val_loss: 0.0014 - val_mse: 0.0014 - val_RMSE: 0.0374 - 1s/epoch - 2ms/step\n",
      "Epoch 36/92\n",
      "764/764 - 1s - loss: 2.3471e-04 - mse: 2.3471e-04 - RMSE: 0.0153 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0361 - 1s/epoch - 2ms/step\n",
      "Epoch 37/92\n",
      "764/764 - 1s - loss: 2.4162e-04 - mse: 2.4162e-04 - RMSE: 0.0155 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0360 - 1s/epoch - 2ms/step\n",
      "Epoch 38/92\n",
      "764/764 - 1s - loss: 2.2701e-04 - mse: 2.2701e-04 - RMSE: 0.0151 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0354 - 1s/epoch - 2ms/step\n",
      "Epoch 39/92\n",
      "764/764 - 1s - loss: 2.1443e-04 - mse: 2.1443e-04 - RMSE: 0.0146 - val_loss: 0.0016 - val_mse: 0.0016 - val_RMSE: 0.0400 - 1s/epoch - 2ms/step\n",
      "Epoch 40/92\n",
      "764/764 - 1s - loss: 2.3885e-04 - mse: 2.3885e-04 - RMSE: 0.0155 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0355 - 1s/epoch - 2ms/step\n",
      "Epoch 41/92\n",
      "764/764 - 1s - loss: 2.2000e-04 - mse: 2.2000e-04 - RMSE: 0.0148 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0382 - 1s/epoch - 2ms/step\n",
      "Epoch 42/92\n",
      "764/764 - 1s - loss: 2.2466e-04 - mse: 2.2466e-04 - RMSE: 0.0150 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0352 - 1s/epoch - 2ms/step\n",
      "Epoch 43/92\n",
      "764/764 - 1s - loss: 2.1539e-04 - mse: 2.1539e-04 - RMSE: 0.0147 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0382 - 1s/epoch - 2ms/step\n",
      "Epoch 44/92\n",
      "764/764 - 1s - loss: 2.2581e-04 - mse: 2.2581e-04 - RMSE: 0.0150 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0350 - 1s/epoch - 2ms/step\n",
      "Epoch 45/92\n",
      "764/764 - 1s - loss: 2.1181e-04 - mse: 2.1181e-04 - RMSE: 0.0146 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0360 - 1s/epoch - 2ms/step\n",
      "Epoch 46/92\n",
      "764/764 - 1s - loss: 1.7127e-04 - mse: 1.7127e-04 - RMSE: 0.0131 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0348 - 1s/epoch - 2ms/step\n",
      "Epoch 47/92\n",
      "764/764 - 1s - loss: 2.0505e-04 - mse: 2.0505e-04 - RMSE: 0.0143 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0366 - 1s/epoch - 2ms/step\n",
      "Epoch 48/92\n",
      "764/764 - 1s - loss: 2.0225e-04 - mse: 2.0225e-04 - RMSE: 0.0142 - val_loss: 0.0020 - val_mse: 0.0020 - val_RMSE: 0.0447 - 1s/epoch - 2ms/step\n",
      "Epoch 49/92\n",
      "764/764 - 1s - loss: 2.0790e-04 - mse: 2.0790e-04 - RMSE: 0.0144 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0350 - 1s/epoch - 2ms/step\n",
      "Epoch 50/92\n",
      "764/764 - 1s - loss: 1.7635e-04 - mse: 1.7635e-04 - RMSE: 0.0133 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0347 - 1s/epoch - 2ms/step\n",
      "Epoch 51/92\n",
      "764/764 - 1s - loss: 1.7717e-04 - mse: 1.7717e-04 - RMSE: 0.0133 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0343 - 1s/epoch - 2ms/step\n",
      "Epoch 52/92\n",
      "764/764 - 1s - loss: 1.8621e-04 - mse: 1.8621e-04 - RMSE: 0.0136 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0345 - 1s/epoch - 2ms/step\n",
      "Epoch 53/92\n",
      "764/764 - 1s - loss: 1.8433e-04 - mse: 1.8433e-04 - RMSE: 0.0136 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0352 - 1s/epoch - 2ms/step\n",
      "Epoch 54/92\n",
      "764/764 - 1s - loss: 1.8399e-04 - mse: 1.8399e-04 - RMSE: 0.0136 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0358 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/92\n",
      "764/764 - 1s - loss: 1.6044e-04 - mse: 1.6044e-04 - RMSE: 0.0127 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0349 - 1s/epoch - 2ms/step\n",
      "Epoch 56/92\n",
      "764/764 - 1s - loss: 1.7189e-04 - mse: 1.7189e-04 - RMSE: 0.0131 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0343 - 1s/epoch - 2ms/step\n",
      "Epoch 57/92\n",
      "764/764 - 1s - loss: 1.6850e-04 - mse: 1.6850e-04 - RMSE: 0.0130 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0365 - 1s/epoch - 2ms/step\n",
      "Epoch 58/92\n",
      "764/764 - 1s - loss: 1.6947e-04 - mse: 1.6947e-04 - RMSE: 0.0130 - val_loss: 0.0014 - val_mse: 0.0014 - val_RMSE: 0.0372 - 1s/epoch - 2ms/step\n",
      "Epoch 59/92\n",
      "764/764 - 2s - loss: 1.6992e-04 - mse: 1.6992e-04 - RMSE: 0.0130 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0347 - 2s/epoch - 2ms/step\n",
      "Epoch 60/92\n",
      "764/764 - 2s - loss: 1.5877e-04 - mse: 1.5877e-04 - RMSE: 0.0126 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0359 - 2s/epoch - 2ms/step\n",
      "Epoch 61/92\n",
      "764/764 - 1s - loss: 1.7343e-04 - mse: 1.7343e-04 - RMSE: 0.0132 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0345 - 1s/epoch - 2ms/step\n",
      "Epoch 62/92\n",
      "764/764 - 1s - loss: 1.4269e-04 - mse: 1.4269e-04 - RMSE: 0.0119 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0345 - 1s/epoch - 2ms/step\n",
      "Epoch 63/92\n",
      "764/764 - 1s - loss: 1.5663e-04 - mse: 1.5663e-04 - RMSE: 0.0125 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0344 - 1s/epoch - 2ms/step\n",
      "Epoch 64/92\n",
      "764/764 - 1s - loss: 1.5313e-04 - mse: 1.5313e-04 - RMSE: 0.0124 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0385 - 1s/epoch - 2ms/step\n",
      "Epoch 65/92\n",
      "764/764 - 1s - loss: 1.7558e-04 - mse: 1.7558e-04 - RMSE: 0.0133 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0345 - 1s/epoch - 2ms/step\n",
      "Epoch 66/92\n",
      "764/764 - 1s - loss: 1.4595e-04 - mse: 1.4595e-04 - RMSE: 0.0121 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0344 - 1s/epoch - 2ms/step\n",
      "Epoch 67/92\n",
      "764/764 - 1s - loss: 1.4622e-04 - mse: 1.4622e-04 - RMSE: 0.0121 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0349 - 1s/epoch - 2ms/step\n",
      "Epoch 68/92\n",
      "764/764 - 1s - loss: 1.5349e-04 - mse: 1.5349e-04 - RMSE: 0.0124 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0362 - 1s/epoch - 2ms/step\n",
      "Epoch 69/92\n",
      "764/764 - 1s - loss: 1.6945e-04 - mse: 1.6945e-04 - RMSE: 0.0130 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0351 - 1s/epoch - 2ms/step\n",
      "Epoch 70/92\n",
      "764/764 - 1s - loss: 1.4351e-04 - mse: 1.4351e-04 - RMSE: 0.0120 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0383 - 1s/epoch - 2ms/step\n",
      "Epoch 71/92\n",
      "764/764 - 1s - loss: 1.6632e-04 - mse: 1.6632e-04 - RMSE: 0.0129 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0350 - 1s/epoch - 2ms/step\n",
      "Epoch 72/92\n",
      "764/764 - 1s - loss: 1.3656e-04 - mse: 1.3656e-04 - RMSE: 0.0117 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0346 - 1s/epoch - 2ms/step\n",
      "Epoch 73/92\n",
      "764/764 - 1s - loss: 1.3184e-04 - mse: 1.3184e-04 - RMSE: 0.0115 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0349 - 1s/epoch - 2ms/step\n",
      "Epoch 74/92\n",
      "764/764 - 1s - loss: 1.5918e-04 - mse: 1.5918e-04 - RMSE: 0.0126 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0367 - 1s/epoch - 2ms/step\n",
      "Epoch 75/92\n",
      "764/764 - 1s - loss: 1.4995e-04 - mse: 1.4995e-04 - RMSE: 0.0122 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0342 - 1s/epoch - 2ms/step\n",
      "Epoch 76/92\n",
      "764/764 - 1s - loss: 1.6476e-04 - mse: 1.6476e-04 - RMSE: 0.0128 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0352 - 1s/epoch - 2ms/step\n",
      "Epoch 77/92\n",
      "764/764 - 1s - loss: 1.1870e-04 - mse: 1.1870e-04 - RMSE: 0.0109 - val_loss: 0.0014 - val_mse: 0.0014 - val_RMSE: 0.0371 - 1s/epoch - 2ms/step\n",
      "Epoch 78/92\n",
      "764/764 - 1s - loss: 1.3268e-04 - mse: 1.3268e-04 - RMSE: 0.0115 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0357 - 1s/epoch - 2ms/step\n",
      "Epoch 79/92\n",
      "764/764 - 1s - loss: 2.1924e-04 - mse: 2.1924e-04 - RMSE: 0.0148 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0346 - 1s/epoch - 2ms/step\n",
      "Epoch 80/92\n",
      "764/764 - 1s - loss: 1.2265e-04 - mse: 1.2265e-04 - RMSE: 0.0111 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0345 - 1s/epoch - 2ms/step\n",
      "Epoch 81/92\n",
      "764/764 - 1s - loss: 1.2208e-04 - mse: 1.2208e-04 - RMSE: 0.0110 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0355 - 1s/epoch - 2ms/step\n",
      "Epoch 82/92\n",
      "764/764 - 1s - loss: 1.2637e-04 - mse: 1.2637e-04 - RMSE: 0.0112 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0343 - 1s/epoch - 2ms/step\n",
      "Epoch 83/92\n",
      "764/764 - 1s - loss: 1.2732e-04 - mse: 1.2732e-04 - RMSE: 0.0113 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0342 - 1s/epoch - 2ms/step\n",
      "Epoch 84/92\n",
      "764/764 - 1s - loss: 1.2458e-04 - mse: 1.2458e-04 - RMSE: 0.0112 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0350 - 1s/epoch - 2ms/step\n",
      "Epoch 85/92\n",
      "764/764 - 1s - loss: 1.4697e-04 - mse: 1.4697e-04 - RMSE: 0.0121 - val_loss: 0.0015 - val_mse: 0.0015 - val_RMSE: 0.0386 - 1s/epoch - 2ms/step\n",
      "Epoch 86/92\n",
      "764/764 - 1s - loss: 1.4294e-04 - mse: 1.4294e-04 - RMSE: 0.0120 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0346 - 1s/epoch - 2ms/step\n",
      "Epoch 87/92\n",
      "764/764 - 1s - loss: 1.2272e-04 - mse: 1.2272e-04 - RMSE: 0.0111 - val_loss: 0.0013 - val_mse: 0.0013 - val_RMSE: 0.0356 - 1s/epoch - 2ms/step\n",
      "Epoch 88/92\n",
      "764/764 - 1s - loss: 1.5879e-04 - mse: 1.5879e-04 - RMSE: 0.0126 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0345 - 1s/epoch - 2ms/step\n",
      "Epoch 89/92\n",
      "764/764 - 1s - loss: 1.0940e-04 - mse: 1.0940e-04 - RMSE: 0.0105 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0344 - 1s/epoch - 2ms/step\n",
      "Epoch 90/92\n",
      "764/764 - 1s - loss: 1.0439e-04 - mse: 1.0439e-04 - RMSE: 0.0102 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0343 - 1s/epoch - 2ms/step\n",
      "Epoch 91/92\n",
      "764/764 - 1s - loss: 1.2306e-04 - mse: 1.2306e-04 - RMSE: 0.0111 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0347 - 1s/epoch - 2ms/step\n",
      "Epoch 92/92\n",
      "764/764 - 1s - loss: 1.1840e-04 - mse: 1.1840e-04 - RMSE: 0.0109 - val_loss: 0.0012 - val_mse: 0.0012 - val_RMSE: 0.0339 - 1s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# fit RNN model\n",
    "num_epochs = 92 # 550\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(X_train_seq_padded,y_train,epochs=num_epochs,batch_size=batch_size,\n",
    "                   validation_data=(X_test_seq_padded, y_test),\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d1e775",
   "metadata": {},
   "source": [
    "#### Save the training history into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd1c7139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_MSE</th>\n",
       "      <th>val_RMSE</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.034441</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.034251</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.011093</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.034665</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.033944</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss       MSE      RMSE  val_loss   val_MSE  val_RMSE  epoch\n",
       "87  0.000159  0.000159  0.012601  0.001190  0.001190  0.034500     87\n",
       "88  0.000109  0.000109  0.010459  0.001186  0.001186  0.034441     88\n",
       "89  0.000104  0.000104  0.010217  0.001173  0.001173  0.034251     89\n",
       "90  0.000123  0.000123  0.011093  0.001202  0.001202  0.034665     90\n",
       "91  0.000118  0.000118  0.010881  0.001152  0.001152  0.033944     91"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist = hist.rename(columns={'mse': 'MSE','val_mse': 'val_MSE'})\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b22ba4",
   "metadata": {},
   "source": [
    "#### Save the final trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0090fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the trained mode\n",
    "# pickle.dump(model, open('keras_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec5c59b",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/serialization_and_saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dfabcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras_model_k.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6477e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'build'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# It can be used to reconstruct the model identically.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m reconstructed_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras_model_k.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/saving/saving_api.py:230\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    239\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:275\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    272\u001b[0m             asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:240\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 240\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _VARS_FNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_filenames:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:710\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    708\u001b[0m     compile_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compile_config:\n\u001b[0;32m--> 710\u001b[0m         \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompile_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[1;32m    713\u001b[0m     record_object_after_deserialization(\n\u001b[1;32m    714\u001b[0m         instance, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    715\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3582\u001b[0m, in \u001b[0;36mModel.compile_from_config\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   3579\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m   3580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m   3581\u001b[0m     \u001b[38;5;66;03m# Create optimizer variables.\u001b[39;00m\n\u001b[0;32m-> 3582\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:997\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hyper:\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_hyper(name)\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:987\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Overridden to support hyperparameter access.\"\"\"\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;66;03m# Needed to avoid infinite recursion with __setattr__.\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hyper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'build'"
     ]
    }
   ],
   "source": [
    "# It can be used to reconstruct the model identically.\n",
    "reconstructed_model = tf.keras.models.load_model(\"keras_model_k.keras\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check:\n",
    "np.testing.assert_allclose(\n",
    "    model.predict(test_input), reconstructed_model.predict(test_input)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7013014",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7456eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98fdc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2643b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/r4/61_m3nz133bcpt1gp9t0vyq00000gn/T/tmpy7axnvka/tf_Saved_Model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/r4/61_m3nz133bcpt1gp9t0vyq00000gn/T/tmpy7axnvka/tf_Saved_Model/assets\n"
     ]
    }
   ],
   "source": [
    "tf_Saved_Model_save_path = os.path.join(tmpdir, \"tf_Saved_Model\")\n",
    "tf.saved_model.save(model, tf_Saved_Model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaa5eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(tf_Saved_Model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9629ab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n"
     ]
    }
   ],
   "source": [
    "print(list(loaded.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af9ff8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense_3': TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_3')}\n"
     ]
    }
   ],
   "source": [
    "infer = loaded.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9daa9fe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_UserObject' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_load \u001b[38;5;241m=\u001b[39m \u001b[43mloaded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(X_test_seq_padded)\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_UserObject' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "pred_load = loaded.predict(X_test_seq_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bf389",
   "metadata": {},
   "source": [
    "#### Reverse both the transformation and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9dcc77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
