{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56c9a02",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# DSI 37 Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17bea6",
   "metadata": {},
   "source": [
    "<a id='part_ii'></a>\n",
    "[Part I](Part_1-Data_Collection.ipynb#part_i) <br>\n",
    "[Part III](Part_3-EDA_and_Modeling.ipynb#part_iii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ab44a",
   "metadata": {},
   "source": [
    "# Part II: Prepare Training Data\n",
    "This section encompasses Part 2 of 3 in the project code, dedicated to the preparation of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40067cb",
   "metadata": {},
   "source": [
    "<a id='part_ii'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7578e",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "[1. Glossary](#glossary)<br>\n",
    "[2. Import Libraries](#import)<br>\n",
    "[3. Load Datasets](#load_datasets)<br>\n",
    "[4. Preprocessing](#preprocessing)<br>\n",
    "[5. Run Topic Based Sentiment Analysis on Posts](#sentiment_posts)<br>\n",
    "[6. Run Topic Based Sentiment Analysis on Comments](#sentiment_comments)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a9b2d",
   "metadata": {},
   "source": [
    "<a id='glossary'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b78d8",
   "metadata": {},
   "source": [
    "## 1. Glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc675a2",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "The data dictionary for the 3 datasets utilized in this section is provided below for reference.\n",
    "\n",
    "`video_info_audio_caption_cleaned_df`\n",
    "\n",
    "|Feature|Type|Description|\n",
    "|:---|:---:|:---|\n",
    "|<b>id</b>|*object*|Id of the TikTok post|\n",
    "|<b>url</b>|*object*|URL address of the TikTok post|\n",
    "|<b>account_name</b>|*object*|Account name of the TikTok post uploader|\n",
    "|<b>following_count</b>| *int64*|Following count of the TikTok post uploader|\n",
    "|<b>follower_count</b>|*object*|Follower count of the TikTok post uploader|\n",
    "|<b>total_like_count</b>|*object*|Total like count of the TikTok post uploader|\n",
    "|<b>date</b>|*object*|Date on which the TikTok post was uploaded|\n",
    "|<b>href</b>|*object*|The href needed to access the link to the TikTok post uploader's account page|\n",
    "|<b>handle</b>|*object*|TikTok post uploader's account handle|\n",
    "|<b>description</b>|*object*|Description of the TikTok post|\n",
    "|<b>hashtag</b>|*object*|Hashtags of the TikTok post|\n",
    "|<b>like_count</b>|*object*|Like count of the TikTok post|\n",
    "|<b>bookmark_count</b>|*object*|Bookmark count of the TikTok post|\n",
    "|<b>share_count</b>|*object*|Share count of the TikTok post|\n",
    "|<b>comment_count</b>|*object*|Comment count of the TikTok post|\n",
    "|<b>final_text</b>|*object*|Text from speech-to-text, unless empty, and if empty, it will be text from caption-to-text |\n",
    "\n",
    "<br>\n",
    "\n",
    "`comments_df`\n",
    "\n",
    "|Feature|Type|Description|\n",
    "|:---|:---:|:---|\n",
    "|<b>id</b>|*object*|Id of the post with indication of being a comment instead of post|\n",
    "|<b>url</b>|*object*|URL address of the TikTok post|\n",
    "|<b>handle</b>|*object*|TikTok post uploader's account handle|\n",
    "|<b>comment_count</b>| *object*|Comment count of the TikTok post|\n",
    "|<b>comment</b>|*object*|Comment text|\n",
    "\n",
    "<br>\n",
    "\n",
    "`sg_entities_patterns_df`\n",
    "\n",
    "|Feature|Type|Description|\n",
    "|:---|:---:|:---|\n",
    "|<b>label</b>|*object*|Label of the tourist attraction (entity)|\n",
    "|<b>pattern</b>|*object*|Pattern to recognize as tourist attraction (entity)|\n",
    "|<b>sublocation</b>|*object*|Actual name of the tourist attraction (entity)|\n",
    "|<b>interest_1</b>| *object*|Main category in which the tourist attraction falls under|\n",
    "|<b>interest_2</b>|*object*|Secondary category in which the tourist attraction falls under|\n",
    "|<b>indoor_outdoor</b>|*object*|Whether the tourist attraction is indoors or outdoors|\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ceefc",
   "metadata": {},
   "source": [
    "<a id='import'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceabcf7f",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966ef666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy\n",
    "# pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a25a2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e207cbf",
   "metadata": {},
   "source": [
    "<a id='load_datasets'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeda776",
   "metadata": {},
   "source": [
    "## 3. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24cb2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info_audio_caption_cleaned_df = pd.read_csv('../datasets/video_info_audio_caption_cleaned.csv')\n",
    "sg_entities_patterns_df = pd.read_csv('../datasets/sg_entities_patterns.csv')\n",
    "comments_df = pd.read_csv('../datasets/comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ad98a",
   "metadata": {},
   "source": [
    "<a id='preprocessing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba14d7",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7d5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08dad79",
   "metadata": {},
   "source": [
    "#### Preprocess `sg_entities_patterns_df`. This dataframe contains a list of Singapore's tourist attractions which we prepared. We shall lemmatize the list so that it can be matched to the lemmatized text later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abea3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# define function for lemmatization using spaCy\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = ' '.join(token.lemma_ for token in doc)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e473cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all text to lowercase\n",
    "sg_entities_patterns_df['pattern'] = sg_entities_patterns_df['pattern'].apply(lambda x: x.lower())\n",
    "# lemmatize text using function defined above\n",
    "sg_entities_patterns_df['pattern'] = sg_entities_patterns_df['pattern'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c13284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_entities_patterns_df.to_csv('../datasets/sg_entities_patterns.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba97d226",
   "metadata": {},
   "source": [
    "#### Preprocess `video_info_audio_caption_cleaned_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e16512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401 entries, 0 to 400\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                401 non-null    object\n",
      " 1   url               401 non-null    object\n",
      " 2   account_name      401 non-null    object\n",
      " 3   following_count   401 non-null    int64 \n",
      " 4   follower_count    401 non-null    object\n",
      " 5   total_like_count  401 non-null    object\n",
      " 6   date              401 non-null    object\n",
      " 7   href              401 non-null    object\n",
      " 8   handle            401 non-null    object\n",
      " 9   description       387 non-null    object\n",
      " 10  hashtag           401 non-null    object\n",
      " 11  like_count        401 non-null    object\n",
      " 12  bookmark_count    401 non-null    object\n",
      " 13  share_count       401 non-null    object\n",
      " 14  comment_count     401 non-null    object\n",
      " 15  final_text        358 non-null    object\n",
      "dtypes: int64(1), object(15)\n",
      "memory usage: 50.2+ KB\n"
     ]
    }
   ],
   "source": [
    "video_info_audio_caption_cleaned_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2a37fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>account_name</th>\n",
       "      <th>following_count</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>total_like_count</th>\n",
       "      <th>date</th>\n",
       "      <th>href</th>\n",
       "      <th>handle</th>\n",
       "      <th>description</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>like_count</th>\n",
       "      <th>bookmark_count</th>\n",
       "      <th>share_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_post</td>\n",
       "      <td>https://www.tiktok.com/@montanadarby/video/7232388092764671258</td>\n",
       "      <td>Montana | Travels</td>\n",
       "      <td>149</td>\n",
       "      <td>95.5K</td>\n",
       "      <td>4.8M</td>\n",
       "      <td>2023-5-12</td>\n",
       "      <td>/@montanadarby</td>\n",
       "      <td>montanadarby</td>\n",
       "      <td>The perfect 48 hour itinerary for Singapore!</td>\n",
       "      <td>['singapore', 'singaporetravel', 'travel']</td>\n",
       "      <td>36.7K</td>\n",
       "      <td>25K</td>\n",
       "      <td>5008</td>\n",
       "      <td>208</td>\n",
       "      <td>How to spend the perfect 48 hours in Singapore? First, head to your waterfall at Singapore airport, it's absolutely incredible and not to be missed. Then, head to the center and drop by the Future World Exhibition at the Art Science Museum. Next, you have to head to Gardens by the Bay, it's completely free to walk around here and just look how amazing it is. Don't forget to buy tickets for the Skyway for the most insane views of the Floral Fantasy, for a magical indoor garden escape. And of course, you have to catch one of the free light shows. Start early to head to one of the most iconic photo spots in Singapore, the Fort Canning tunnel. Then it's time for a quick stroll along Arab Street for the most incredible foods of Sultan mosque before stopping by Crack.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_post</td>\n",
       "      <td>https://www.tiktok.com/@trippingmillennial/video/7194849267461426478</td>\n",
       "      <td>Travel with Rachael ‚úàÔ∏è</td>\n",
       "      <td>474</td>\n",
       "      <td>57.1K</td>\n",
       "      <td>1.8M</td>\n",
       "      <td>2023-1-31</td>\n",
       "      <td>/@trippingmillennial</td>\n",
       "      <td>trippingmillennial</td>\n",
       "      <td>Hawker centers are my love language</td>\n",
       "      <td>['southeastasia', 'singapore', 'travelsingapore']</td>\n",
       "      <td>4913</td>\n",
       "      <td>3686</td>\n",
       "      <td>806</td>\n",
       "      <td>31</td>\n",
       "      <td>Skip to Singapore, kind of feels like a trip into the future, and if you visit, here are five can't-miss things that you should do. First, Singapore is pricey, but thankfully, the Hawker centres are not. These food halls are a great way to sample some of Singapore's Best Foods; it's really cheap; some of them are Michelin-starred, and it's a good way to get to the local culture. To using the incredible Gardens by the bay. While most of this area is actually free to explore, I recommend springing for tickets to the Skywalk along with the cloud forest and the beautiful Flower Dome. Don't miss the night show here either (more on that later). Period which is a beautiful, quirky, colorful, fun place to explore, even when it's raining; it's a good place to shop and get a beer and people watched. The trip to the iconic Marina Bay Sands Hotel; definitely don't skip on the historic Raffles hotel, which is a beautiful example of British colonial architecture, and don't miss their Long Bar, which is famous for the Singapore Sling cocktail. Thanks and follow for More Travel content.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_post</td>\n",
       "      <td>https://www.tiktok.com/@montanadarby/video/7217039897687887109</td>\n",
       "      <td>Montana | Travels</td>\n",
       "      <td>149</td>\n",
       "      <td>95.5K</td>\n",
       "      <td>4.8M</td>\n",
       "      <td>2023-4-1</td>\n",
       "      <td>/@montanadarby</td>\n",
       "      <td>montanadarby</td>\n",
       "      <td>The ultimate guide on the BEST things to do Singapore! Can you believe most of these things are completely FREE!!</td>\n",
       "      <td>['singapore', 'singaporethingstodo', 'marinabaysands', 'jewelchangi', 'gardensbythebay', 'backpacking']</td>\n",
       "      <td>73.7K</td>\n",
       "      <td>40.3K</td>\n",
       "      <td>10.5K</td>\n",
       "      <td>609</td>\n",
       "      <td>Sky Garden at Capita Spring free. Jewel fountain at Changi Airport free. OCBC Skyway ¬£7.30. fort canning walk / tunnel free. arab street free. Gardens by the bay light show free. level 33 rooftop bar free entry. floral fantasy exhibition ¬£9.10. spectra light show free. future world at art science museum ¬£9.20.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_post</td>\n",
       "      <td>https://www.tiktok.com/@aktravelss/video/7208911518451223813</td>\n",
       "      <td>AKTRAVELS ‚úàÔ∏è üåç</td>\n",
       "      <td>129</td>\n",
       "      <td>130.2K</td>\n",
       "      <td>8.4M</td>\n",
       "      <td>2023-3-10</td>\n",
       "      <td>/@aktravelss</td>\n",
       "      <td>aktravelss</td>\n",
       "      <td>Singapore is just different üá∏üá¨</td>\n",
       "      <td>['singapore', 'singaporetiktok', 'singaporelife', 'shopping', 'traveltiktok', 'aktravels']</td>\n",
       "      <td>2.1M</td>\n",
       "      <td>292.8K</td>\n",
       "      <td>25.1K</td>\n",
       "      <td>11.7K</td>\n",
       "      <td>shopping in singapore, LOUIS VUITTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_post</td>\n",
       "      <td>https://www.tiktok.com/@belemartorres2/video/7218172665222237441</td>\n",
       "      <td>Belemar Torres</td>\n",
       "      <td>440</td>\n",
       "      <td>1284</td>\n",
       "      <td>37.2K</td>\n",
       "      <td>2023-4-4</td>\n",
       "      <td>/@belemartorres2</td>\n",
       "      <td>belemartorres2</td>\n",
       "      <td>Here‚Äôs my top 20 most visited place in Singapore!</td>\n",
       "      <td>['singapore2023', 'travelsingapore', 'solotraveling', 'fyp']</td>\n",
       "      <td>10.1K</td>\n",
       "      <td>7756</td>\n",
       "      <td>1935</td>\n",
       "      <td>71</td>\n",
       "      <td>top 20 places to visit, merlion park, marina bay sands fountain show, skypark / celavi, helix bridge, gardens by the bay, haji lane, bali lane, sultan mosque, chinatown, little india, arab street, orchard, raffles hotel, sentosa sea aquarium, universal studios, cable car, fort canning tree tunnel, jewel changi airport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0  0_post   \n",
       "1  1_post   \n",
       "2  2_post   \n",
       "3  3_post   \n",
       "4  4_post   \n",
       "\n",
       "                                                                    url  \\\n",
       "0        https://www.tiktok.com/@montanadarby/video/7232388092764671258   \n",
       "1  https://www.tiktok.com/@trippingmillennial/video/7194849267461426478   \n",
       "2        https://www.tiktok.com/@montanadarby/video/7217039897687887109   \n",
       "3          https://www.tiktok.com/@aktravelss/video/7208911518451223813   \n",
       "4      https://www.tiktok.com/@belemartorres2/video/7218172665222237441   \n",
       "\n",
       "             account_name  following_count follower_count total_like_count  \\\n",
       "0       Montana | Travels              149          95.5K             4.8M   \n",
       "1  Travel with Rachael ‚úàÔ∏è              474          57.1K             1.8M   \n",
       "2       Montana | Travels              149          95.5K             4.8M   \n",
       "3          AKTRAVELS ‚úàÔ∏è üåç              129         130.2K             8.4M   \n",
       "4          Belemar Torres              440           1284            37.2K   \n",
       "\n",
       "        date                  href              handle  \\\n",
       "0  2023-5-12        /@montanadarby        montanadarby   \n",
       "1  2023-1-31  /@trippingmillennial  trippingmillennial   \n",
       "2   2023-4-1        /@montanadarby        montanadarby   \n",
       "3  2023-3-10          /@aktravelss          aktravelss   \n",
       "4   2023-4-4      /@belemartorres2      belemartorres2   \n",
       "\n",
       "                                                                                                         description  \\\n",
       "0                                                                       The perfect 48 hour itinerary for Singapore!   \n",
       "1                                                                                Hawker centers are my love language   \n",
       "2  The ultimate guide on the BEST things to do Singapore! Can you believe most of these things are completely FREE!!   \n",
       "3                                                                                     Singapore is just different üá∏üá¨   \n",
       "4                                                                  Here‚Äôs my top 20 most visited place in Singapore!   \n",
       "\n",
       "                                                                                                   hashtag  \\\n",
       "0                                                               ['singapore', 'singaporetravel', 'travel']   \n",
       "1                                                        ['southeastasia', 'singapore', 'travelsingapore']   \n",
       "2  ['singapore', 'singaporethingstodo', 'marinabaysands', 'jewelchangi', 'gardensbythebay', 'backpacking']   \n",
       "3               ['singapore', 'singaporetiktok', 'singaporelife', 'shopping', 'traveltiktok', 'aktravels']   \n",
       "4                                             ['singapore2023', 'travelsingapore', 'solotraveling', 'fyp']   \n",
       "\n",
       "  like_count bookmark_count share_count comment_count  \\\n",
       "0      36.7K            25K        5008           208   \n",
       "1       4913           3686         806            31   \n",
       "2      73.7K          40.3K       10.5K           609   \n",
       "3       2.1M         292.8K       25.1K         11.7K   \n",
       "4      10.1K           7756        1935            71   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        final_text  \n",
       "0                                                                                                                                                                                                                                                                                                                             How to spend the perfect 48 hours in Singapore? First, head to your waterfall at Singapore airport, it's absolutely incredible and not to be missed. Then, head to the center and drop by the Future World Exhibition at the Art Science Museum. Next, you have to head to Gardens by the Bay, it's completely free to walk around here and just look how amazing it is. Don't forget to buy tickets for the Skyway for the most insane views of the Floral Fantasy, for a magical indoor garden escape. And of course, you have to catch one of the free light shows. Start early to head to one of the most iconic photo spots in Singapore, the Fort Canning tunnel. Then it's time for a quick stroll along Arab Street for the most incredible foods of Sultan mosque before stopping by Crack.  \n",
       "1  Skip to Singapore, kind of feels like a trip into the future, and if you visit, here are five can't-miss things that you should do. First, Singapore is pricey, but thankfully, the Hawker centres are not. These food halls are a great way to sample some of Singapore's Best Foods; it's really cheap; some of them are Michelin-starred, and it's a good way to get to the local culture. To using the incredible Gardens by the bay. While most of this area is actually free to explore, I recommend springing for tickets to the Skywalk along with the cloud forest and the beautiful Flower Dome. Don't miss the night show here either (more on that later). Period which is a beautiful, quirky, colorful, fun place to explore, even when it's raining; it's a good place to shop and get a beer and people watched. The trip to the iconic Marina Bay Sands Hotel; definitely don't skip on the historic Raffles hotel, which is a beautiful example of British colonial architecture, and don't miss their Long Bar, which is famous for the Singapore Sling cocktail. Thanks and follow for More Travel content.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Sky Garden at Capita Spring free. Jewel fountain at Changi Airport free. OCBC Skyway ¬£7.30. fort canning walk / tunnel free. arab street free. Gardens by the bay light show free. level 33 rooftop bar free entry. floral fantasy exhibition ¬£9.10. spectra light show free. future world at art science museum ¬£9.20.  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            shopping in singapore, LOUIS VUITTON   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  top 20 places to visit, merlion park, marina bay sands fountain show, skypark / celavi, helix bridge, gardens by the bay, haji lane, bali lane, sultan mosque, chinatown, little india, arab street, orchard, raffles hotel, sentosa sea aquarium, universal studios, cable car, fort canning tree tunnel, jewel changi airport  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_info_audio_caption_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2fedf",
   "metadata": {},
   "source": [
    "#### Combine caption / audio to text with description as many videos do not repeat the information provided in the description, whereas the caption and audio to text are typically vert similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f81c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info_audio_caption_cleaned_df['final_text_description'] = video_info_audio_caption_cleaned_df['final_text'] + ' ' + video_info_audio_caption_cleaned_df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e65d0fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401 entries, 0 to 400\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   id                      401 non-null    object\n",
      " 1   url                     401 non-null    object\n",
      " 2   account_name            401 non-null    object\n",
      " 3   following_count         401 non-null    int64 \n",
      " 4   follower_count          401 non-null    object\n",
      " 5   total_like_count        401 non-null    object\n",
      " 6   date                    401 non-null    object\n",
      " 7   href                    401 non-null    object\n",
      " 8   handle                  401 non-null    object\n",
      " 9   description             387 non-null    object\n",
      " 10  hashtag                 401 non-null    object\n",
      " 11  like_count              401 non-null    object\n",
      " 12  bookmark_count          401 non-null    object\n",
      " 13  share_count             401 non-null    object\n",
      " 14  comment_count           401 non-null    object\n",
      " 15  final_text              358 non-null    object\n",
      " 16  final_text_description  347 non-null    object\n",
      "dtypes: int64(1), object(16)\n",
      "memory usage: 53.4+ KB\n"
     ]
    }
   ],
   "source": [
    "video_info_audio_caption_cleaned_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf273e6",
   "metadata": {},
   "source": [
    "#### Convert `following_count`, `follower_count`, `total_like_count`, `like_count`, `bookmark_count`, `share_count`, `comment_count` to numbers as those with more than thousands or millions will have a 'K' or 'M' appended at the back of a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff3efab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info_audio_caption_cleaned_df['following_count'] = video_info_audio_caption_cleaned_df['following_count'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d3c1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that converts string that ends with 'M' or 'K' to an integer\n",
    "def convert_value(value):\n",
    "    if value.endswith('M'):\n",
    "        return int(float(value[:-1]) * 1000000)\n",
    "    elif value.endswith('K'):\n",
    "        return int(float(value[:-1]) * 1000)\n",
    "    else:\n",
    "        return int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e291888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function to all columns with counts\n",
    "lst_counts = ['following_count','follower_count','total_like_count','like_count','bookmark_count','share_count',\n",
    "              'comment_count']\n",
    "for i in lst_counts:\n",
    "    video_info_audio_caption_cleaned_df[i] = video_info_audio_caption_cleaned_df[i].apply(lambda x: convert_value(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46c40e",
   "metadata": {},
   "source": [
    "#### Create a new column that has the number of hashtags used in the post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f287318e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['singapore', 'singaporetravel', 'travel']\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_info_audio_caption_cleaned_df['hashtag'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfa33272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string of list into a list\n",
    "video_info_audio_caption_cleaned_df['hashtag'] = video_info_audio_caption_cleaned_df['hashtag'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77bbc2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['singapore', 'singaporetravel', 'travel']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if it is now a list\n",
    "video_info_audio_caption_cleaned_df['hashtag'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "153d0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of hashtags\n",
    "video_info_audio_caption_cleaned_df['num_hashtags'] = video_info_audio_caption_cleaned_df['hashtag'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd9ad261",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      3\n",
       "2      6\n",
       "3      6\n",
       "4      4\n",
       "      ..\n",
       "396    0\n",
       "397    4\n",
       "398    3\n",
       "399    3\n",
       "400    6\n",
       "Name: num_hashtags, Length: 401, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_info_audio_caption_cleaned_df['num_hashtags']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9644c6",
   "metadata": {},
   "source": [
    "#### Save as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9dcab056",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info_audio_caption_cleaned_df.to_csv('../datasets/video_info_audio_caption_cleaned_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0594b4",
   "metadata": {},
   "source": [
    "<a id='sentiment_posts'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f719d87",
   "metadata": {},
   "source": [
    "## 5. Run Topic Based Sentiment Analysis on Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4218fc3e",
   "metadata": {},
   "source": [
    "#### Instantiate `train_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e71c1d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_comment</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity</th>\n",
       "      <th>pos_sentiment_words</th>\n",
       "      <th>neg_sentiment_words</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [post_comment, id, sentence, entity, pos_sentiment_words, neg_sentiment_words, sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate dataframe\n",
    "train_df = pd.DataFrame(columns=['post_comment','id','sentence','entity','pos_sentiment_words','neg_sentiment_words','sentiment'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990f549a",
   "metadata": {},
   "source": [
    "#### Using spaCy‚Äôs rule-based matcher and `sg_entities_patterns_df`, we will be able to extract Singapore's tourist attractions as entities. To do so, we will convert `sg_entities_patterns_df` to a list of dictionary and add them as patterns to the rule-based matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "273e8a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# create entity ruler\n",
    "ruler = nlp.add_pipe('entity_ruler',\"ruleActions\", config={\"overwrite_ents\": True})\n",
    "\n",
    "# list of entities and patterns\n",
    "# note that the text are lemmatized before pulling for entities. Thus, patterns should be in root form\n",
    "lst_of_patterns = sg_entities_patterns_df.to_dict('records') # convert df to list of dictionary\n",
    "patterns = lst_of_patterns\n",
    "\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb42142",
   "metadata": {},
   "source": [
    "#### Here, we will split the posts into sentences. For each sentence, we will extract entities, positive and/or negative sentiment words and sentiment score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d49cd17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find no. of rows in 'video_info_audio_caption_cleaned_df'\n",
    "n_rows = len(video_info_audio_caption_cleaned_df)\n",
    "\n",
    "for i in range(0,n_rows):\n",
    "    # define text\n",
    "    text = video_info_audio_caption_cleaned_df['final_text_description'].loc[i]\n",
    "    \n",
    "    # if there are no words in 'final_text_description', it becomes a math nan which is a float\n",
    "    # thus, to check if there are words, check if type is string or float\n",
    "    if type(text) == str:\n",
    "        # split text into smaller sentences\n",
    "        sentences = re.split(r'[^\\w\\s\\'-,]', text) # NOT a word character, whitespace, single quote, hyphen, or comma\n",
    "\n",
    "        for sentence in sentences:\n",
    "            # instantiate a dictionary\n",
    "            dictionary = {}\n",
    "\n",
    "            # since this is a post, save this in 'post_comment'\n",
    "            dictionary['post_comment'] = 'post' \n",
    "            \n",
    "            # save the 'post_id'\n",
    "            dictionary['id'] = video_info_audio_caption_cleaned_df['id'].loc[i]\n",
    "\n",
    "            # convert characters to lowercase\n",
    "            sentence = sentence.lower()\n",
    "            # remove punctuations\n",
    "            sentence = sentence.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "            # check if there are words in the sentence\n",
    "            if sentence != '' and sentence != ' ':\n",
    "                # save the sentence in dictionary\n",
    "                dictionary['sentence'] = sentence\n",
    "\n",
    "                # instantiate 'pos_sentiment_words' and 'neg_sentiment_words'\n",
    "                dictionary['pos_sentiment_words'] = []\n",
    "                dictionary['neg_sentiment_words'] = []\n",
    "                for token in sentence.split():\n",
    "                    textblob_token = TextBlob(token)\n",
    "                    if textblob_token.sentiment.polarity > 0:\n",
    "                        dictionary['pos_sentiment_words'].append(token)\n",
    "                    elif textblob_token.sentiment.polarity < 0:\n",
    "                        dictionary['neg_sentiment_words'].append(token)\n",
    "\n",
    "                # lemmatize text using function defined above\n",
    "                lemmatized_text = lemmatize_text(sentence)\n",
    "                lemmatized_doc = nlp(lemmatized_text)\n",
    "\n",
    "                # extract entities \n",
    "                entities = [entity for entity in lemmatized_doc.ents]\n",
    "\n",
    "                for entity in entities:\n",
    "\n",
    "                    # if word happens to be in the name of entity, it should not be a sentiment word, remove from pos words\n",
    "                    for word in dictionary['pos_sentiment_words']:\n",
    "                        if word in str(entity):\n",
    "                            dictionary['pos_sentiment_words'].remove(word)\n",
    "                            sentence = sentence.replace(word,'')\n",
    "                    # if word happens to be in the name of entity, it should not be a sentiment word, remove from neg words\n",
    "                    for word in dictionary['neg_sentiment_words']:\n",
    "                        if word in str(entity):\n",
    "                            dictionary['neg_sentiment_words'].remove(word)\n",
    "                            sentence = sentence.replace(word,'')\n",
    "\n",
    "                textblob_sentence = TextBlob(sentence)\n",
    "                dictionary['sentiment'] = textblob_sentence.sentiment.polarity\n",
    "\n",
    "                dictionary['entity'] = []\n",
    "                for entity in entities:\n",
    "                    # save the entity in the dictionary\n",
    "                    dictionary['entity'].append(str(entity))\n",
    "\n",
    "                # save the entire dictionary to train_df\n",
    "                train_df.loc[len(train_df)] = dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e330f",
   "metadata": {},
   "source": [
    "#### Check the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67d84446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1411 entries, 0 to 1410\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   post_comment         1411 non-null   object \n",
      " 1   id                   1411 non-null   object \n",
      " 2   sentence             1411 non-null   object \n",
      " 3   entity               1411 non-null   object \n",
      " 4   pos_sentiment_words  1411 non-null   object \n",
      " 5   neg_sentiment_words  1411 non-null   object \n",
      " 6   sentiment            1411 non-null   float64\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 88.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4380bafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_comment</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity</th>\n",
       "      <th>pos_sentiment_words</th>\n",
       "      <th>neg_sentiment_words</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>post</td>\n",
       "      <td>435_post</td>\n",
       "      <td>i feel like its the las vegas of asia but actually not quite there yet</td>\n",
       "      <td>[the las vegas, asia]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>post</td>\n",
       "      <td>435_post</td>\n",
       "      <td>dont get me wrong their gardens are so pretty and i loved walking through everything but there is just no natural substance to the country</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pretty, loved, natural]</td>\n",
       "      <td>[wrong]</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>post</td>\n",
       "      <td>435_post</td>\n",
       "      <td>so these are the reasons why i dont like singapore</td>\n",
       "      <td>[singapore]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>post</td>\n",
       "      <td>435_post</td>\n",
       "      <td>if you are actually from singapore and disagree on what i just said i am open to hearing your feedback so comment down below</td>\n",
       "      <td>[singapore]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[down]</td>\n",
       "      <td>-0.051852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>post</td>\n",
       "      <td>435_post</td>\n",
       "      <td>im sorry singapore</td>\n",
       "      <td>[singapore]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sorry]</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_comment        id  \\\n",
       "1406         post  435_post   \n",
       "1407         post  435_post   \n",
       "1408         post  435_post   \n",
       "1409         post  435_post   \n",
       "1410         post  435_post   \n",
       "\n",
       "                                                                                                                                         sentence  \\\n",
       "1406                                                                       i feel like its the las vegas of asia but actually not quite there yet   \n",
       "1407   dont get me wrong their gardens are so pretty and i loved walking through everything but there is just no natural substance to the country   \n",
       "1408                                                                                           so these are the reasons why i dont like singapore   \n",
       "1409                 if you are actually from singapore and disagree on what i just said i am open to hearing your feedback so comment down below   \n",
       "1410                                                                                                                          im sorry singapore    \n",
       "\n",
       "                     entity       pos_sentiment_words neg_sentiment_words  \\\n",
       "1406  [the las vegas, asia]                        []                  []   \n",
       "1407                     []  [pretty, loved, natural]             [wrong]   \n",
       "1408            [singapore]                        []                  []   \n",
       "1409            [singapore]                        []              [down]   \n",
       "1410            [singapore]                        []             [sorry]   \n",
       "\n",
       "      sentiment  \n",
       "1406   0.000000  \n",
       "1407   0.100000  \n",
       "1408   0.000000  \n",
       "1409  -0.051852  \n",
       "1410  -0.500000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63391fd",
   "metadata": {},
   "source": [
    "#### Save the dataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3bd6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../datasets/train_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79d56b",
   "metadata": {},
   "source": [
    "<a id='sentiment_comments'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d27c13",
   "metadata": {},
   "source": [
    "## 6. Run Topic Based Sentiment Analysis on Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "932eb265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20015 entries, 0 to 20014\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             20015 non-null  object\n",
      " 1   url            20015 non-null  object\n",
      " 2   handle         20015 non-null  object\n",
      " 3   comment_count  20015 non-null  object\n",
      " 4   comment        20015 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 782.0+ KB\n"
     ]
    }
   ],
   "source": [
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12487e8",
   "metadata": {},
   "source": [
    "#### Here, we will split the comments into sentences. For each sentence, we will extract entities, positive and/or negative sentiment words and sentiment score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7dc5c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find no. of rows in 'video_info_audio_caption_cleaned_df'\n",
    "n_rows = len(comments_df)\n",
    "\n",
    "for i in range(0,n_rows):\n",
    "    # define text\n",
    "    text = comments_df['comment'].loc[i]\n",
    "    \n",
    "    # if there are no words in 'final_text_description', it becomes a math nan which is a float\n",
    "    # thus, to check if there are words, check if type is string or float\n",
    "    if type(text) == str:\n",
    "        # split text into smaller sentences\n",
    "        sentences = re.split(r'[^\\w\\s\\'-,]', text) # NOT a word character, whitespace, single quote, hyphen, or comma\n",
    "\n",
    "        for sentence in sentences:\n",
    "            # instantiate a dictionary\n",
    "            dictionary = {}\n",
    "\n",
    "            # since this is a post, save this in 'post_comment'\n",
    "            dictionary['post_comment'] = 'post' \n",
    "            \n",
    "            # save the 'post_id'\n",
    "            dictionary['id'] = comments_df['id'].loc[i]\n",
    "\n",
    "            # convert characters to lowercase\n",
    "            sentence = sentence.lower()\n",
    "            # remove punctuations\n",
    "            sentence = sentence.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "            # check if there are words in the sentence\n",
    "            if sentence != '' and sentence != ' ':\n",
    "                # save the sentence in dictionary\n",
    "                dictionary['sentence'] = sentence\n",
    "\n",
    "                # instantiate 'pos_sentiment_words' and 'neg_sentiment_words'\n",
    "                dictionary['pos_sentiment_words'] = []\n",
    "                dictionary['neg_sentiment_words'] = []\n",
    "                for token in sentence.split():\n",
    "                    textblob_token = TextBlob(token)\n",
    "                    if textblob_token.sentiment.polarity > 0:\n",
    "                        dictionary['pos_sentiment_words'].append(token)\n",
    "                    elif textblob_token.sentiment.polarity < 0:\n",
    "                        dictionary['neg_sentiment_words'].append(token)\n",
    "\n",
    "                # lemmatize text using function defined above\n",
    "                lemmatized_text = lemmatize_text(sentence)\n",
    "                lemmatized_doc = nlp(lemmatized_text)\n",
    "\n",
    "                # extract entities \n",
    "                entities = [entity for entity in lemmatized_doc.ents]\n",
    "\n",
    "                for entity in entities:\n",
    "\n",
    "                    # if word happens to be in the name of entity, it should not be a sentiment word, remove from pos words\n",
    "                    for word in dictionary['pos_sentiment_words']:\n",
    "                        if word in str(entity):\n",
    "                            dictionary['pos_sentiment_words'].remove(word)\n",
    "                            sentence = sentence.replace(word,'')\n",
    "                    # if word happens to be in the name of entity, it should not be a sentiment word, remove from neg words\n",
    "                    for word in dictionary['neg_sentiment_words']:\n",
    "                        if word in str(entity):\n",
    "                            dictionary['neg_sentiment_words'].remove(word)\n",
    "                            sentence = sentence.replace(word,'')\n",
    "\n",
    "                textblob_sentence = TextBlob(sentence)\n",
    "                dictionary['sentiment'] = textblob_sentence.sentiment.polarity\n",
    "\n",
    "                dictionary['entity'] = []\n",
    "                for entity in entities:\n",
    "                    # save the entity in the dictionary\n",
    "                    dictionary['entity'].append(str(entity))\n",
    "\n",
    "                # save the entire dictionary to train_df\n",
    "                train_df.loc[len(train_df)] = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2dae4998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_comment</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity</th>\n",
       "      <th>pos_sentiment_words</th>\n",
       "      <th>neg_sentiment_words</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31335</th>\n",
       "      <td>post</td>\n",
       "      <td>435_cmt</td>\n",
       "      <td>locals</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31336</th>\n",
       "      <td>post</td>\n",
       "      <td>435_cmt</td>\n",
       "      <td>you complained singaporeans are rude bec of your experience with 1 taxi driver</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[complained, rude]</td>\n",
       "      <td>-0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31337</th>\n",
       "      <td>post</td>\n",
       "      <td>435_cmt</td>\n",
       "      <td>i felt sorry for your friend if he is a singaporean</td>\n",
       "      <td>[singaporean]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sorry]</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31338</th>\n",
       "      <td>post</td>\n",
       "      <td>435_cmt</td>\n",
       "      <td>next time do a bit of googling before going to a new place</td>\n",
       "      <td>[]</td>\n",
       "      <td>[new]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.068182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31339</th>\n",
       "      <td>post</td>\n",
       "      <td>435_cmt</td>\n",
       "      <td>these opinions sound ignorant</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sound]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_comment       id  \\\n",
       "31335         post  435_cmt   \n",
       "31336         post  435_cmt   \n",
       "31337         post  435_cmt   \n",
       "31338         post  435_cmt   \n",
       "31339         post  435_cmt   \n",
       "\n",
       "                                                                             sentence  \\\n",
       "31335                                                                          locals   \n",
       "31336  you complained singaporeans are rude bec of your experience with 1 taxi driver   \n",
       "31337                             i felt sorry for your friend if he is a singaporean   \n",
       "31338                      next time do a bit of googling before going to a new place   \n",
       "31339                                                   these opinions sound ignorant   \n",
       "\n",
       "              entity pos_sentiment_words neg_sentiment_words  sentiment  \n",
       "31335             []                  []                  []   0.000000  \n",
       "31336            [1]                  []  [complained, rude]  -0.300000  \n",
       "31337  [singaporean]                  []             [sorry]  -0.500000  \n",
       "31338             []               [new]                  []   0.068182  \n",
       "31339             []             [sound]                  []   0.400000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f727a",
   "metadata": {},
   "source": [
    "#### Save the dataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74550c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../datasets/train_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f20a15c",
   "metadata": {},
   "source": [
    "## <b> End of Part II</b> <br>\n",
    "[Part I](Part_1-Data_Collection.ipynb#part_i) <br>\n",
    "[Part III](Part_3-EDA_and_Modeling.ipynb#part_iii)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
